# LAKEHOUSE

## Iceberg как формат таблиц

В качестве базы был выбран формат таблиц **Iceberg**, так как он обладает рядом преимуществ:

- Соблюдение **ACID-принципов** (атомарность изменений, изоляция пользователей).
- В отличие от **S3**, которое не обладает строгой консистентностью.
- Поддержка **эволюции схемы данных** без изменения нижележащих Parquet-файлов.
- Эффективная работа с **S3**: изначально это простое объектное хранилище, а Iceberg добавляет логику работы с данными и метаданными.

---

## Как работает Iceberg

Iceberg напрямую зависит от каталога, где хранится metadata. Основная структура:

<img width="1160" height="612" alt="image" src="https://github.com/user-attachments/assets/208642f5-15d8-4219-958c-38d8f44a1360" />

- Iceberg хранит в snapshot-файлах ссылки на **manifest list**.
- **Manifest list** содержит пути к manifest-файлам.
- **Manifest-файлы** содержат ссылки на физические файлы с данными (Parquet).
- Так как воркеров (читателей) может быть несколько, файлов тоже несколько.

---

## Time Travel

Iceberg позволяет заглянуть в прошлое:  
можно запросить таблицу в состоянии **7 дней назад**, если старые версии не были удалены.

---

## Версионирование с Nessie

В нашем случае используется каталог **Nessie**, который позволяет вести версионирование данных в стиле Git:

- Ветки, форки, слияния.  
- Разным пользователям можно отдавать разные "корни" (версии).

---

## Сборщик мусора

Iceberg из коробки поддерживает очистку неактуальных данных:

<img width="421" height="296" alt="image" src="https://github.com/user-attachments/assets/7086633b-bb9b-4ced-aa7e-3e5fb9e27a28" />

---

## Выбор движка: Spark или Flink

После выбора формата и каталога необходимо определиться с инструментом обработки.

### Apache Spark
- Оптимален для **batch-задач**.
- Сильная экосистема библиотек (**MLlib, SQL, GraphX** и др.).
- Удобен для работы в Jupyter Notebook и IDE.
- Подходит для сложных агрегаций, аналитики, оптимизаций (например, **Z-ordering**).

### Apache Flink
- Ориентирован на **streaming** и события в реальном времени.
- Сильная сторона — обработка непрерывных потоков данных.
- Лучше интегрируется в **продакшн-окружение**.

В связке они позволяют обрабатывать как **исторические batch-данные**, так и **потоки событий**.  
На их уровне выполняются:
- Партиционирование.  
- Слияние мелких файлов (**compaction**).  
- Оптимизации доступа к данным.  

---

## Оркестрация с Dagster

**Dagster** выступает как оркестратор:

- Проверяет, поступили ли новые данные в **S3**.
- Проверяет, обрабатывались ли они ранее.
- Запускает Spark/Flink Job для очистки и нормализации данных.
- На этом шаге подключается **Great Expectations** (валидация качества данных).
- Загружает данные в каталог **silver**:
  - Партиционированные Parquet-файлы.
  - Metadata.
  - Схема таблицы.

---

## Great Expectations

**Great Expectations** позволяет:

- Проверять качество данных (валидность, полноту, уникальность).
- Фиксировать ожидания (**expectations**) и автоматически формировать отчёты.
- Легко интегрироваться в пайплайн (Spark/Flink).

---

## Этап агрегирования данных

Далее мы собираем бизнес-требования и определяем ключевые метрики.

- Пишем отдельную Spark/Flink Job для выборки данных из **silver-слоя**.
- Выполняем агрегации и готовим данные к загрузке в **Postgres**.
- Подключаем BI-инструмент (**Insight**) для аналитики.  

Эти джобы специфичны под бизнес-задачи каждой ИС, поэтому они не универсальны.

---

## Использование Dremio / Drill

На этом этапе также могут применяться:

- **Apache Dremio** / **Apache Drill**
- Используются для **интерактивного анализа данных**.
- Позволяют выполнять SQL-запросы по данным в Lakehouse.
- Удобны для ad-hoc аналитики, когда нужно проверить гипотезу без написания ETL job.

---

## Архитектурная схема

<img width="1036" height="1083" alt="image" src="https://github.com/user-attachments/assets/e82e03ee-475e-4734-825a-0051055c98fc" />


---

## Итоги: Плюсы и Минусы

### Плюсы
- Пользуемся всеми преимуществами **Parquet**.  
- Умеем эффективно модифицировать строки (частично обновлять и удалять).  
- Поддержка эволюции схемы.  
- **ACID** и прозрачный COMMIT (данные не теряются).  
- Есть **MVCC** — писатели не конфликтуют с читателями (даже на Serializable).  
- Наличие каталога для реализации продвинутых техник управления данными.  

### Минусы
- Оставляем много мусора, который надо убирать.  
- Уборка мусора может конфликтовать с работой с данными (**MVCC**).  
- Большое количество метаданных, которые читаются на этапе планирования.  
- Сложный многоуровневый этап планирования (**Spark driver, Trino Coordinator**).  
