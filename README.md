# LAKEHOUSE

## Iceberg как формат таблиц

В качестве базы был выбран формат таблиц **Apache Iceberg**, так как он обладает рядом преимуществ:

- Соблюдение **ACID-принципов** (атомарность изменений, изоляция пользователей).
- В отличие от **S3**, которое не обладает строгой консистентностью.
- Поддержка **эволюции схемы данных** без изменения нижележащих Parquet-файлов.
- Эффективная работа с **объектными хранилищами**: Iceberg добавляет слой логики поверх S3/MinIO для работы с данными и метаданными.

---

## Роль MinIO

**MinIO** в архитектуре выполняет роль S3-совместимого объектного хранилища:

- Хранение слоёв данных (**bronze → silver → gold**).
- Совместимость с экосистемой Hadoop, Spark, Flink, Trino.
- Высокая скорость доступа и возможность горизонтального масштабирования.
- Безопасность: поддержка политики прав доступа и шифрования.

---

## Как работает Iceberg

Iceberg напрямую зависит от каталога, где хранится metadata.

**Основная структура:**
- Iceberg хранит в **snapshot-файлах** ссылки на **manifest list**.
- **Manifest list** содержит пути к manifest-файлам.
- **Manifest-файлы** содержат ссылки на физические файлы с данными (Parquet).
- Так как воркеров (читателей) может быть несколько, файлов тоже несколько.

<p align="center">
  <img width="600" alt="iceberg-structure" src="https://github.com/user-attachments/assets/208642f5-15d8-4219-958c-38d8f44a1360" />
</p>

---

## Time Travel

Iceberg позволяет заглянуть в прошлое:  
можно запросить таблицу в состоянии **7 дней назад**, если старые версии не были удалены.

---

## Версионирование с Nessie

В нашем случае используется каталог **Project Nessie**, который позволяет вести версионирование данных в стиле Git:

- Ветки, форки, слияния.  
- Разным пользователям можно отдавать разные "корни" (версии).

---

## Зачем нужны партиционирование и оптимизации

- **Партиционирование**: данные делятся на части по ключу (например, `dt`, `region`), что позволяет ускорять фильтрацию и чтение.
- **Z-ordering**: дополнительная сортировка по нескольким колонкам для оптимизации range-запросов.
- **Compaction (слияние файлов)**: уменьшение числа мелких файлов для снижения нагрузки на метаданные и планировщики.
- Все эти операции повышают скорость запросов, но создают новые файлы, что ведёт к накоплению "мусора".

---

## Сборщик мусора

Iceberg из коробки поддерживает очистку неактуальных данных:

- Удаляет старые **snapshots** и их метаданные.
- Чистит ссылки на неиспользуемые **manifest** и **Parquet-файлы**.
- Но **оставляем много мусора**, потому что:
  - Каждая оптимизация (партиционирование, Z-ordering, compaction) порождает новые файлы.
  - Старые версии этих файлов тоже нужно удалять.
  - Поэтому Iceberg требует **регулярного запуска maintenance job**:
    - Очистка старых снапшотов.
    - Compaction свежих партиций.
    - (опционально) пересортировка через Z-ordering.

⚠️ Если не выполнять уборку, Lakehouse превращается в "болото" из тысяч мелких файлов — типичная проблема дата-озёр.

<p align="center">
  <img width="400" alt="gc-iceberg" src="https://github.com/user-attachments/assets/7086633b-bb9b-4ced-aa7e-3e5fb9e27a28" />
</p>

---

## Выбор движка: Spark или Flink

После выбора формата и каталога необходимо определиться с инструментом обработки.

### Apache Spark
- Оптимален для **batch-задач**.
- Сильная экосистема библиотек (**MLlib, SQL, GraphX** и др.).
- Удобен для работы в Jupyter Notebook и IDE.
- Подходит для сложных агрегаций, аналитики, оптимизаций (например, **Z-ordering**).

### Apache Flink
- Ориентирован на **streaming** и события в реальном времени.
- Сильная сторона — обработка непрерывных потоков данных.
- Лучше интегрируется в **продакшн-окружение**.

В связке они позволяют обрабатывать как **исторические batch-данные**, так и **потоки событий**.  
На их уровне выполняются:
- Партиционирование.  
- Слияние мелких файлов (**compaction**).  
- Оптимизации доступа к данным.  

---

## Оркестрация с Dagster

**Dagster** выступает как оркестратор:

1. Проверяет, поступили ли новые данные в **MinIO/S3**.
2. Проверяет, обрабатывались ли они ранее.
3. Запускает Spark/Flink Job для очистки и нормализации данных.
4. Подключает **Great Expectations** (валидация качества данных).
5. Загружает данные в каталог **silver**:
   - Партиционированные Parquet-файлы.
   - Metadata.
   - Схема таблицы.

---

## Great Expectations

**Great Expectations** позволяет:

- Проверять качество данных (валидность, полноту, уникальность).
- Фиксировать ожидания (**expectations**) и автоматически формировать отчёты.
- Легко интегрироваться в пайплайн (Spark/Flink).

---

## Этап агрегирования данных

Далее мы собираем бизнес-требования и определяем ключевые метрики:

- Пишем отдельные Spark/Flink Job для выборки данных из **silver-слоя**.
- Выполняем агрегации и готовим данные к загрузке в **Postgres**.
- Подключаем BI-инструмент (**Insight**) для аналитики.  

Эти джобы специфичны под бизнес-задачи каждой ИС, поэтому они не универсальны.

---

## Использование Dremio / Drill

- **Apache Dremio** / **Apache Drill** используются для интерактивного анализа.
- Позволяют выполнять SQL-запросы напрямую по данным в Lakehouse.
- Удобны для ad-hoc аналитики, когда нужно проверить гипотезу без написания ETL job.

---

## Архитектурная схема

<p align="center">
  <img width="600" alt="lakehouse-architecture" src="https://github.com/user-attachments/assets/e82e03ee-475e-4734-825a-0051055c98fc" />
</p>

---

## Итоги: Плюсы и Минусы

### Плюсы
- Пользуемся всеми преимуществами **Parquet**.  
- Эффективные модификации строк (частично обновлять и удалять).  
- Поддержка эволюции схемы.  
- **ACID** и прозрачный COMMIT.  
- Есть **MVCC** — писатели не конфликтуют с читателями.  
- Наличие каталога для реализации продвинутых техник управления данными.  

### Минусы
- Постоянно оставляем "мусор" (старые файлы, снапшоты).  
- Уборка мусора может конфликтовать с активными транзакциями.  
- Большое количество метаданных замедляет планирование.  
- Сложный многоуровневый этап планирования (**Spark driver, Trino Coordinator**).  
